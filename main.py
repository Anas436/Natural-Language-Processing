from PIL import Image
import streamlit as st
from streamlit_option_menu import option_menu

# Configuring Streamlit
st.set_page_config(page_title="Omdena Giza", page_icon=":bird:", initial_sidebar_state="expanded")

hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
css_style = {
    "icon": {"color": "white"},
    "nav-link": {"--hover-color": "grey"},
    "nav-link-selected": {"background-color": "#1624A9"},
}

# Loading assets
img_banner = Image.open("assets/images/banner.png")
img_giza = Image.open("assets/images/giza-logo.png")


def home_page():
    st.write(f"""# NLP with Disaster Tweets""", unsafe_allow_html=True)
    st.image(img_banner)

    st.write("""<h2>Project background</h2>
        <p>Natural Language Processing (NLP) is a rapidly evolving field of computer science that deals with 
        the interactions between human language and computers. In recent years, NLP has been applied to a variety of 
        real-world problems, including the analysis of social media data during natural disasters. Social media platforms 
        like Twitter are rich sources of real-time information about disaster events, and NLP techniques can be used to 
        extract useful information from the text data generated by users during these events.</p><br> 
        <h2>The Problem</h2> 
        <p>The analysis of social media data during natural disasters can be 
        challenging due to the sheer volume of data generated and the need to quickly identify relevant information. 
        Additionally, tweets are often short, informal, and contain non-standard language, making them difficult to 
        analyse using traditional NLP techniques. As a result, there is a need for more advanced NLP techniques that can 
        accurately classify disaster-related tweets and extract relevant information in real-time.
        <br><br>
        The dataset provided for this challenge consists of a collection of tweets that have been labelled as either 
        “disaster” or “not disaster”. The goal is to build a model that can learn to distinguish between the two classes 
        based on the text content of the tweets. The challenge is designed to test participants’ skills in natural language 
        processing (NLP) and machine learning. It requires them to preprocess the text data, perform feature engineering, 
        and build a model that can accurately classify tweets.</p> 
        <h2>Project goals</h2> 
        <p>The goals of Natural Language Processing with Disaster Tweets research 
        are: - To explore the current state-of-the-art in NLP techniques for disaster tweet analysis, including tweet 
        classification and sentiment analysis. - Text Preprocessing. - Model Development: We will try to apply machine 
        learning, and deep learning models including RNN and Transformers. - Evaluate Model. - Compare the performance of 
        machine learning and deep learning (RNNS and Transformers). - App Deployment.</p>""",
             unsafe_allow_html=True)


def model_section():
    st.error("No model to show for now")


def contributors_page():
    def contributors():
        for i in range(10):
            st.write("- contributor name")

    col1, col2, col3 = st.columns(3)
    with col1:
        contributors()
    with col2:
        contributors()
    with col3:
        contributors()


with st.sidebar:
    st.image(img_giza)
    selected = option_menu(
        menu_title=None,  # required
        options=["Home", "Model", "Contributors"],
        icons=["house", "gear", "people"],
        styles=css_style
    )

if selected == "Home":
    home_page()

elif selected == "Model":
    model_section()

elif selected == "Contributors":
    st.write("<h1 style='text-align:center;'>A heartfelt thankyou to all of our contributors ❤️</h1> <hr><br>",
             unsafe_allow_html=True)
    contributors_page()
