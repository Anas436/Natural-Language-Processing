import openai
from PIL import Image
import streamlit as st
from streamlit_chat import message
from streamlit_option_menu import option_menu

# openai.api_key = os.getenv('OPENAI_API')
# secret_text = os.getenv('NLP_TEXT')

openai.api_key = st.secrets('OPENAI_API')
secret_text = st.secrets('NLP_TEXT')


def nlp_model(input_message):
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=(secret_text + str(input_message)),
        max_tokens=300,
        n=1,
        stop=None,
        temperature=0.5
    )
    return " ".join(response.choices[0].text.split("\n\n")[1:])


# Configuring Streamlit
st.set_page_config(page_title="Omdena Giza", page_icon=":bird:", initial_sidebar_state="expanded")

hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
css_style = {
    "icon": {"color": "white"},
    "nav-link": {"--hover-color": "grey"},
    "nav-link-selected": {"background-color": "#1624A9"},
}

# Loading assets
img_banner = Image.open("assets/images/banner.png")
img_giza = Image.open("assets/images/giza-logo.png")


def home_page():
    st.write(f"""# NLP with Disaster Tweets""", unsafe_allow_html=True)
    st.image(img_banner)

    st.write("""
        <h2>The Problem</h2> 
        <p>The analysis of social media data during natural disasters can be 
        challenging due to the sheer volume of data generated and the need to quickly identify relevant information. 
        Additionally, tweets are often short, informal, and contain non-standard language, making them difficult to 
        analyse using traditional NLP techniques. As a result, there is a need for more advanced NLP techniques that can 
        accurately classify disaster-related tweets and extract relevant information in real-time.
        <br><br>
        The dataset provided for this challenge consists of a collection of tweets that have been labelled as either 
        “disaster” or “not disaster”. The goal is to build a model that can learn to distinguish between the two classes 
        based on the text content of the tweets. The challenge is designed to test participants’ skills in natural language 
        processing (NLP) and machine learning. It requires them to preprocess the text data, perform feature engineering, 
        and build a model that can accurately classify tweets.</p> 
        <h2>Project background</h2>
        <p>Natural Language Processing (NLP) is a rapidly evolving field of computer science that deals with 
        the interactions between human language and computers. In recent years, NLP has been applied to a variety of 
        real-world problems, including the analysis of social media data during natural disasters. Social media platforms 
        like Twitter are rich sources of real-time information about disaster events, and NLP techniques can be used to 
        extract useful information from the text data generated by users during these events.</p><br> 
        """, unsafe_allow_html=True)


def model_section():
    st.write("# Natural Language Processing with Disaster Tweets")
    uploaded_text = st.text_input('Type the tweet here', placeholder="Paste your tweet here", label_visibility="hidden")

    if uploaded_text:
        response = nlp_model(uploaded_text)

        message(uploaded_text, is_user=True, avatar_style="identicon")

        if response == "Disaster.":
            message("The tweet is related to disaster.", avatar_style="shapes")
            st.error("## Disaster related tweet detected.")
        elif response in ["Not disaster.", "No."]:
            message("The tweet is not related to a disaster.", avatar_style="shapes")
            st.success("### No disasters detected.")
        else:
            message(response)


def contributors_page():
    def contributors():
        for i in range(10):
            st.write("- contributor name")

    col1, col2, col3 = st.columns(3)
    with col1:
        contributors()
    with col2:
        contributors()
    with col3:
        contributors()


with st.sidebar:
    st.image(img_giza)
    selected = option_menu(
        menu_title=None,  # required
        options=["Home", "NLP Model", "Contributors"],
        icons=["house", "gear", "people"],
        styles=css_style
    )

if selected == "Home":
    home_page()

elif selected == "NLP Model":
    model_section()

elif selected == "Contributors":
    st.write("<h1 style='text-align:center;'>A heartfelt thankyou to all our contributors. ❤️</h1> <hr><br>",
             unsafe_allow_html=True)
    contributors_page()
